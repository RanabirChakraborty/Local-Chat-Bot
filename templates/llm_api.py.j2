import os
from fastapi import FastAPI
from pydantic import BaseModel
from transformers import pipeline
import uvicorn

app = FastAPI()

# Disable GPU if not available
os.environ["CUDA_VISIBLE_DEVICES"] = ""

# Define the request model
class TextRequest(BaseModel):
    prompt: str

llm = pipeline("text-generation", model="facebook/opt-350m")

@app.post("/generate")
async def generate_text(request: TextRequest):
    response = llm(request.prompt, max_length=100)
    return {"response": response[0]["generated_text"]}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port={{ llm_api_port }})
